{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스 편향성 분석 모델\n",
    "\n",
    "이 노트북은 뉴스 기사의 민주당과 국힘에 대한 편향성을 분석하는 딥러닝 모델을 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "df1 = pd.read_csv('../data/labeling1.csv')\n",
    "df2 = pd.read_csv('../data/labeling2.csv')\n",
    "df = pd.concat([df1, df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스탠스 레이블 매핑\n",
    "stance_mapping = {'우호': 0, '중립': 1, '비판': 2}\n",
    "\n",
    "# 민주당과 국힘 스탠스 레이블 변환\n",
    "df['민주당_스탠스_레이블'] = df['민주당_스탠스'].map(stance_mapping)\n",
    "df['국힘_스탠스_레이블'] = df['국힘_스탠스'].map(stance_mapping)\n",
    "\n",
    "# # 텍스트 데이터 준비\n",
    "# df['text'] = df['title_cleaned'] + ' ' + df['content_cleaned']\n",
    "\n",
    "print(f\"전체 데이터 수: {len(df)}\")\n",
    "print(\"\\n민주당 스탠스 분포:\")\n",
    "print(df['민주당_스탠스'].value_counts())\n",
    "print(\"\\n국힘 스탠스 분포:\")\n",
    "print(df['국힘_스탠스'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터셋 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, dem_labels, ppp_labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.dem_labels = dem_labels\n",
    "        self.ppp_labels = ppp_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'dem_label': torch.tensor(self.dem_labels[idx], dtype=torch.long),\n",
    "            'ppp_label': torch.tensor(self.ppp_labels[idx], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsBiasModel(torch.nn.Module):\n",
    "    def __init__(self, model_name, num_labels=3):\n",
    "        super().__init__()\n",
    "        # 기본 모델 로드\n",
    "        self.bert = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "        \n",
    "        # 드롭아웃 레이어 추가\n",
    "        self.dropout = torch.nn.Dropout(0.2)  # 드롭아웃 비율 증가\n",
    "        \n",
    "        # 공통 특성 추출을 위한 레이어\n",
    "        self.shared_layer = torch.nn.Linear(num_labels, 256)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        \n",
    "        # 각 정당별 분류기\n",
    "        self.classifier_dem = torch.nn.Sequential(\n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.1),\n",
    "            torch.nn.Linear(128, num_labels)\n",
    "        )\n",
    "        \n",
    "        self.classifier_ppp = torch.nn.Sequential(\n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.1),\n",
    "            torch.nn.Linear(128, num_labels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, dem_label=None, ppp_label=None):\n",
    "        # BERT 출력\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.logits\n",
    "        \n",
    "        # 공통 특성 추출\n",
    "        shared_features = self.dropout(pooled_output)\n",
    "        shared_features = self.shared_layer(shared_features)\n",
    "        shared_features = self.activation(shared_features)\n",
    "        \n",
    "        # 각 정당별 예측\n",
    "        dem_logits = self.classifier_dem(shared_features)\n",
    "        ppp_logits = self.classifier_ppp(shared_features)\n",
    "        \n",
    "        if dem_label is not None and ppp_label is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            dem_loss = loss_fct(dem_logits, dem_label)\n",
    "            ppp_loss = loss_fct(ppp_logits, ppp_label)\n",
    "            loss = dem_loss + ppp_loss\n",
    "            return {'loss': loss, 'dem_logits': dem_logits, 'ppp_logits': ppp_logits}\n",
    "        \n",
    "        return {'dem_logits': dem_logits, 'ppp_logits': ppp_logits}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 학습 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "train_texts, val_texts, train_dem_labels, val_dem_labels, train_ppp_labels, val_ppp_labels = train_test_split(\n",
    "    df['text'].values,\n",
    "    df['민주당_스탠스_레이블'].values,\n",
    "    df['국힘_스탠스_레이블'].values,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 토크나이저 초기화\n",
    "tokenizer = AutoTokenizer.from_pretrained('beomi/KcELECTRA-base')\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_dataset = NewsDataset(train_texts, train_dem_labels, train_ppp_labels, tokenizer)\n",
    "val_dataset = NewsDataset(val_texts, val_dem_labels, val_ppp_labels, tokenizer)\n",
    "\n",
    "# 모델 초기화\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NewsBiasModel('beomi/KcELECTRA-base').to(device)\n",
    "\n",
    "# 커스텀 데이터 콜레이터\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 평가 함수\n",
    "def compute_metrics(eval_pred):\n",
    "    dem_preds, ppp_preds = eval_pred.predictions\n",
    "    dem_labels, ppp_labels = eval_pred.label_ids\n",
    "    \n",
    "    dem_preds = np.argmax(dem_preds, axis=1)\n",
    "    ppp_preds = np.argmax(ppp_preds, axis=1)\n",
    "    \n",
    "    dem_report = classification_report(dem_labels, dem_preds, target_names=['우호', '중립', '비판'], output_dict=True)\n",
    "    ppp_report = classification_report(ppp_labels, ppp_preds, target_names=['우호', '중립', '비판'], output_dict=True)\n",
    "    \n",
    "    return {\n",
    "        'dem_f1': dem_report['weighted avg']['f1-score'],\n",
    "        'ppp_f1': ppp_report['weighted avg']['f1-score']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 인자 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.05,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='dem_f1',\n",
    "    gradient_accumulation_steps=4,  # 그래디언트 누적\n",
    "    fp16=True,  # 혼합 정밀도 학습\n",
    "    label_smoothing_factor=0.1,  # 레이블 스무딩\n",
    "    optim='adamw_torch'  # AdamW 옵티마이저 사용\n",
    ")\n",
    "\n",
    "# 트레이너 초기화\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 실행\n",
    "trainer.train()\n",
    "\n",
    "# 최종 평가\n",
    "final_metrics = trainer.evaluate()\n",
    "print(\"\\n최종 평가 결과:\")\n",
    "print(f\"민주당 F1 점수: {final_metrics['eval_dem_f1']:.4f}\")\n",
    "print(f\"국힘 F1 점수: {final_metrics['eval_ppp_f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모델 저장 및 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "trainer.save_model('./best_model')\n",
    "tokenizer.save_pretrained('./best_model')\n",
    "\n",
    "# 모델 로드\n",
    "def load_model(model_path):\n",
    "    model = NewsBiasModel('beomi/KcELECTRA-base')\n",
    "    model.load_state_dict(torch.load(f'{model_path}/pytorch_model.bin'))\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 새로운 기사에 대한 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_stance(text, model, tokenizer, device):\n",
    "    model.eval()\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        dem_pred = torch.argmax(outputs['dem_logits'], dim=1).item()\n",
    "        ppp_pred = torch.argmax(outputs['ppp_logits'], dim=1).item()\n",
    "    \n",
    "    return dem_pred, ppp_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_csv_file(csv_path, model, tokenizer, device):\n",
    "    # CSV 파일 로드\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 예측 결과를 저장할 리스트\n",
    "    dem_predictions = []\n",
    "    ppp_predictions = []\n",
    "    \n",
    "    # 각 텍스트에 대해 예측 수행\n",
    "    for text in tqdm(df['text'], desc=\"Predicting\"):\n",
    "        dem_pred, ppp_pred = predict_stance(text, model, tokenizer, device)\n",
    "        dem_predictions.append(dem_pred)\n",
    "        ppp_predictions.append(ppp_pred)\n",
    "    \n",
    "    # 예측 결과를 DataFrame에 추가\n",
    "    df['민주당_스탠스_레이블'] = dem_predictions\n",
    "    df['국힘_스탠스_레이블'] = ppp_predictions\n",
    "    \n",
    "    # 예측 결과를 숫자에서 텍스트로 변환\n",
    "    reverse_mapping = {v: k for k, v in stance_mapping.items()}\n",
    "    df['민주당_스탠스'] = df['민주당_스탠스_레이블'].map(reverse_mapping)\n",
    "    df['국힘_스탠스'] = df['국힘_스탠스_레이블'].map(reverse_mapping)\n",
    "    \n",
    "    # 결과 저장\n",
    "    output_path = csv_path.replace('.csv', '_predicted.csv')\n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    # 예측 결과 통계 출력\n",
    "    print(f\"\\n{csv_path} 예측 결과:\")\n",
    "    print(\"\\n민주당 스탠스 예측 분포:\")\n",
    "    print(df['민주당_스탠스'].value_counts())\n",
    "    print(\"\\n국힘 스탠스 예측 분포:\")\n",
    "    print(df['국힘_스탠스'].value_counts())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 로드\n",
    "model, tokenizer = load_model('./best_model')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# CSV 파일 예측\n",
    "csv_path = \"./data/전체1.csv\"  # 여기에 실제 CSV 파일 경로를 입력하시면 됩니다\n",
    "predicted_df = predict_csv_file(csv_path, model, tokenizer, device)\n",
    "predicted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "predicted_df.to_csv(csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
