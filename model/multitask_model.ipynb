{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴스 편향성 분석 모델\n",
    "\n",
    "이 노트북은 뉴스 기사의 민주당과 국힘에 대한 편향성을 분석하는 딥러닝 모델을 구현합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Anaconda\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModel,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 베이스라인 결과 로드\n",
    "baseline_results = pd.read_csv('./baseline_results/baseline_results.csv').iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 수: 400\n",
      "\n",
      "정당별 기사 수:\n",
      "party\n",
      "민주당     200\n",
      "국민의힘    200\n",
      "Name: count, dtype: int64\n",
      "\n",
      "스탠스 분포:\n",
      "stance_label\n",
      "1    216\n",
      "2    148\n",
      "0     36\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "df = pd.read_csv('../data/라벨링_자동분류결과.csv')\n",
    "\n",
    "# 스탠스 레이블 매핑\n",
    "stance_mapping = {'우호': 0, '중립': 1, '비판': 2}\n",
    "\n",
    "# 스탠스 레이블 변환\n",
    "df['stance_label'] = df['auto_label'].map(stance_mapping)\n",
    "\n",
    "# NaN 값 처리\n",
    "df = df.dropna(subset=['text', 'stance_label'])\n",
    "\n",
    "print(f\"전체 데이터 수: {len(df)}\")\n",
    "print(\"\\n정당별 기사 수:\")\n",
    "print(df['party'].value_counts())\n",
    "print(\"\\n스탠스 분포:\")\n",
    "print(df['stance_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 데이터셋 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsDataset(Dataset):\n",
    "    def __init__(self, texts, stance_labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.stance_labels = stance_labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # 텐서 차원 조정\n",
    "        input_ids = encoding['input_ids'].squeeze(0)  # [max_length]\n",
    "        attention_mask = encoding['attention_mask'].squeeze(0)  # [max_length]\n",
    "        \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'stance_label': torch.tensor(self.stance_labels[idx], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskNewsModel(torch.nn.Module):\n",
    "    def __init__(self, model_name, num_stance_labels=3, num_sentiment_labels=3, mask_token_id=50264):\n",
    "        super().__init__()\n",
    "        # 기본 모델 로드\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.mask_token_id = mask_token_id\n",
    "        \n",
    "        # 드롭아웃 레이어\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "        \n",
    "        # 공통 특성 추출 레이어\n",
    "        hidden_size = self.bert.config.hidden_size\n",
    "        self.shared_layer = torch.nn.Linear(hidden_size, 256)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        \n",
    "        # 스탠스 분류기\n",
    "        self.stance_classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.1),\n",
    "            torch.nn.Linear(128, num_stance_labels)\n",
    "        )\n",
    "        \n",
    "        # 감성 분류기\n",
    "        self.sentiment_classifier = torch.nn.Sequential(\n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.1),\n",
    "            torch.nn.Linear(128, num_sentiment_labels)\n",
    "        )\n",
    "\n",
    "        # 감성 손실 계산용 vocab projection 레이어\n",
    "        self.sentiment_vocab_projection = torch.nn.Linear(hidden_size, self.bert.config.vocab_size)\n",
    "        \n",
    "        # 모델 가중치 초기화\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"모델 가중치 초기화\"\"\"\n",
    "        for module in [self.shared_layer, self.stance_classifier, self.sentiment_classifier]:\n",
    "            for m in module.modules():\n",
    "                if isinstance(m, torch.nn.Linear):\n",
    "                    torch.nn.init.xavier_uniform_(m.weight)\n",
    "                    if m.bias is not None:\n",
    "                        torch.nn.init.zeros_(m.bias)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, stance_label=None):\n",
    "        # BERT 출력\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.last_hidden_state[:, 0, :]  # [CLS] 토큰\n",
    "        \n",
    "        # 공통 특성 추출\n",
    "        shared_features = self.dropout(pooled_output)\n",
    "        shared_features = self.shared_layer(shared_features)\n",
    "        shared_features = self.activation(shared_features)\n",
    "        \n",
    "        # 스탠스 예측\n",
    "        stance_logits = self.stance_classifier(shared_features)\n",
    "        \n",
    "        # 감성 예측\n",
    "        sentiment_logits = self.sentiment_classifier(shared_features)\n",
    "        \n",
    "        if stance_label is not None:\n",
    "            # 스탠스 손실 계산\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            stance_loss = loss_fct(stance_logits, stance_label)\n",
    "            \n",
    "            # 감성 분석 손실 계산\n",
    "            sentiment_loss = self._compute_sentiment_loss(sentiment_logits, input_ids, attention_mask)\n",
    "            \n",
    "            # 총 손실 계산\n",
    "            total_loss = stance_loss + 0.1 * sentiment_loss\n",
    "            \n",
    "            return {\n",
    "                'loss': total_loss,\n",
    "                'stance_logits': stance_logits,\n",
    "                'sentiment_logits': sentiment_logits\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            'stance_logits': stance_logits,\n",
    "            'sentiment_logits': sentiment_logits\n",
    "        }\n",
    "    \n",
    "    def _compute_sentiment_loss(self, sentiment_logits, input_ids, attention_mask):\n",
    "        \"\"\"단순화된 감성 분석 손실 계산\"\"\"\n",
    "        try:\n",
    "            # 마스킹된 입력 생성\n",
    "            masked_input_ids = input_ids.clone()\n",
    "            mask_prob = 0.15\n",
    "        \n",
    "            # 마스킹 마스크 생성 (패딩 토큰 제외)\n",
    "            mask_mask = torch.rand_like(input_ids.float()) < mask_prob\n",
    "            mask_mask = mask_mask & (attention_mask == 1)\n",
    "            \n",
    "            if not mask_mask.any():\n",
    "                return torch.tensor(0.0, device=input_ids.device)\n",
    "            \n",
    "            # 마스킹 적용\n",
    "            mask_token_id = self.mask_token_id\n",
    "            masked_input_ids[mask_mask] = mask_token_id\n",
    "        \n",
    "            # 마스킹된 입력에 대한 예측\n",
    "            # 입력 텐서의 차원 확인 및 조정\n",
    "            if len(masked_input_ids.shape) == 1:\n",
    "                masked_input_ids = masked_input_ids.unsqueeze(0)\n",
    "            if len(attention_mask.shape) == 1:\n",
    "                attention_mask = attention_mask.unsqueeze(0)\n",
    "                \n",
    "            # BERT 모델에 입력\n",
    "            masked_outputs = self.bert(\n",
    "                input_ids=masked_input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                return_dict=True\n",
    "            )\n",
    "            \n",
    "            # 마스킹된 위치의 로짓 추출\n",
    "            last_hidden_state = masked_outputs.last_hidden_state  # [batch_size, seq_len, hidden_size]\n",
    "            masked_positions = mask_mask.nonzero(as_tuple=True)  # (batch_indices, seq_indices)\n",
    "            \n",
    "            # 마스킹된 위치의 로짓만 추출\n",
    "            masked_logits = last_hidden_state[masked_positions]  # [num_masked, hidden_size]\n",
    "            \n",
    "            # 원본 입력과의 차이를 손실로 사용\n",
    "            target_ids = input_ids[mask_mask]  # [num_masked]\n",
    "            \n",
    "            # 로짓을 어휘 크기에 맞게 변환\n",
    "            vocab_size = self.bert.config.vocab_size\n",
    "            \n",
    "            # 로짓 투사 후 CrossEntropyLoss 계산\n",
    "            masked_logits = self.sentiment_vocab_projection(masked_logits)\n",
    "\n",
    "            # 라벨 범위 검증\n",
    "            assert torch.max(target_ids) < vocab_size, f\"target_id max {torch.max(target_ids)} >= vocab size {vocab_size}\"\n",
    "            assert torch.min(target_ids) >= 0, f\"target_id min {torch.min(target_ids)} < 0\"\n",
    "            \n",
    "            # 손실 계산\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            sentiment_loss = loss_fct(masked_logits, target_ids)\n",
    "            \n",
    "            return sentiment_loss\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"감성 분석 손실 계산 중 오류 발생: {str(e)}\")\n",
    "            return torch.tensor(0.0, device=input_ids.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 학습 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "train_texts, val_texts, train_party_labels, val_party_labels, train_stance_labels, val_stance_labels = train_test_split(\n",
    "    df['text'].values,\n",
    "    df['party'].values,\n",
    "    df['stance_label'].values,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저 초기화\n",
    "tokenizer = AutoTokenizer.from_pretrained('klue/roberta-large')\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_dataset = NewsDataset(train_texts, train_stance_labels, tokenizer)\n",
    "val_dataset = NewsDataset(val_texts, val_stance_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 모델 초기화\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 모델 초기화 및 GPU 이동을 분리\n",
    "model = MultiTaskNewsModel('klue/roberta-large', mask_token_id=tokenizer.mask_token_id)\n",
    "model = model.to(device)\n",
    "\n",
    "# 커스텀 데이터 콜레이터\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    stance_preds, sentiment_preds = eval_pred.predictions\n",
    "    stance_labels = eval_pred.label_ids\n",
    "    \n",
    "    stance_preds = np.argmax(stance_preds, axis=1)\n",
    "    sentiment_preds = np.argmax(sentiment_preds, axis=1)\n",
    "    \n",
    "    stance_report = classification_report(\n",
    "        stance_labels, \n",
    "        stance_preds, \n",
    "        target_names=['우호', '중립', '비판'],\n",
    "        output_dict=True\n",
    "    )\n",
    "    \n",
    "    # 감성 분석 결과는 별도로 평가\n",
    "    sentiment_report = {\n",
    "        'score': np.mean(sentiment_preds == 1)  # 중립 클래스의 비율\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'stance_f1': stance_report['weighted avg']['f1-score'],\n",
    "        'stance_accuracy': stance_report['accuracy'],\n",
    "        'sentiment_score': sentiment_report['score']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 인자 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./multitask_results',\n",
    "    num_train_epochs=4,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.05,\n",
    "    logging_dir='./multitask_logs',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='stance_f1',\n",
    "    gradient_accumulation_steps=2,  # 그래디언트 누적\n",
    "    fp16=True,  # 혼합 정밀도 학습\n",
    "    label_smoothing_factor=0.1,  # 레이블 스무딩\n",
    "    optim='adamw_torch'  # AdamW 옵티마이저 사용\n",
    ")\n",
    "\n",
    "# 트레이너 초기화\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2, early_stopping_threshold=0.001)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 학습 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 실행\n",
    "trainer.train()\n",
    "\n",
    "# 최종 평가\n",
    "final_metrics = trainer.evaluate()\n",
    "print(\"\\n최종 평가 결과:\")\n",
    "print(f\"스탠스 F1 점수: {final_metrics['eval_stance_f1']:.4f}\")\n",
    "print(f\"스탠스 정확도: {final_metrics['eval_stance_accuracy']:.4f}\")\n",
    "print(f\"감성 분석 점수: {final_metrics['eval_sentiment_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 베이스라인과 성능 비교\n",
    "comparison_results = {\n",
    "    'Model': ['Baseline', 'Multitask BERT'],\n",
    "    'Stance F1': [baseline_results['stance_f1'], final_metrics['eval_stance_f1']],\n",
    "    'Stance Accuracy': [baseline_results['stance_accuracy'], final_metrics['eval_stance_accuracy']],\n",
    "    'Sentiment F1': [baseline_results['sentiment_f1'], final_metrics['eval_sentiment_f1']],\n",
    "    'Sentiment Accuracy': [baseline_results['sentiment_accuracy'], final_metrics['eval_sentiment_accuracy']]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_results)\n",
    "comparison_df.to_csv('./multitask_results/model_comparison.csv', index=False)\n",
    "comparison_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 향상 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "metrics = ['Stance F1', 'Stance Accuracy', 'Sentiment F1', 'Sentiment Accuracy']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, comparison_df.iloc[0, 1:], width, label='Baseline')\n",
    "plt.bar(x + width/2, comparison_df.iloc[1, 1:], width, label='Multitask BERT')\n",
    "\n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.xticks(x, metrics)\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('./multitask_results/performance_comparison.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 모델 저장 및 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "trainer.save_model('./best_model')\n",
    "tokenizer.save_pretrained('./best_model')\n",
    "\n",
    "# 모델 로드\n",
    "def load_model(model_path):\n",
    "    model = MultiTaskNewsModel('klue/roberta-large')\n",
    "    model.load_state_dict(torch.load(f'{model_path}/pytorch_model.bin'))\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 새로운 기사에 대한 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_news(text, model, tokenizer, device):\n",
    "    model.eval()\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        stance_pred = torch.argmax(outputs['stance_logits'], dim=1).item()\n",
    "        sentiment_pred = torch.argmax(outputs['sentiment_logits'], dim=1).item()\n",
    "    \n",
    "    return stance_pred, sentiment_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_csv_file(csv_path, model, tokenizer, device):\n",
    "    # CSV 파일 로드\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 예측 결과를 저장할 리스트\n",
    "    stance_predictions = []\n",
    "    sentiment_predictions = []\n",
    "    \n",
    "    # 각 텍스트에 대해 예측 수행\n",
    "    for text in tqdm(df['text'], desc=\"Predicting\"):\n",
    "        stance_pred, sentiment_pred = predict_news(text, model, tokenizer, device)\n",
    "        stance_predictions.append(stance_pred)\n",
    "        sentiment_predictions.append(sentiment_pred)\n",
    "    \n",
    "    # 예측 결과를 DataFrame에 추가\n",
    "    df['stance_label'] = stance_predictions\n",
    "    df['sentiment_label'] = sentiment_predictions\n",
    "    \n",
    "    # 예측 결과를 숫자에서 텍스트로 변환\n",
    "    stance_mapping = {v: k for k, v in stance_mapping.items()}\n",
    "    sentiment_mapping = {v: k for k, v in sentiment_mapping.items()}\n",
    "    \n",
    "    df['stance'] = df['stance_label'].map(stance_mapping)\n",
    "    df['sentiment'] = df['sentiment_label'].map(sentiment_mapping)\n",
    "    \n",
    "    # 결과 저장\n",
    "    output_path = csv_path.replace('.csv', '_predicted.csv')\n",
    "    df.to_csv(output_path, index=False)\n",
    "    \n",
    "    # 예측 결과 통계 출력\n",
    "    print(f\"\\n{csv_path} 예측 결과:\")\n",
    "    print(\"\\n스탠스 예측 분포:\")\n",
    "    print(df['stance'].value_counts())\n",
    "    print(\"\\n감성 예측 분포:\")\n",
    "    print(df['sentiment'].value_counts())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 로드\n",
    "model, tokenizer = load_model('./best_model')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# CSV 파일 예측\n",
    "csv_path = \"./data/전체1.csv\"  # 여기에 실제 CSV 파일 경로를 입력하시면 됩니다\n",
    "predicted_df = predict_csv_file(csv_path, model, tokenizer, device)\n",
    "predicted_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "predicted_df.to_csv(csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
